#!/usr/bin/env python3
# -*- coding: utf-8 -*-



from __future__ import annotations
import argparse
from pathlib import Path
from typing import Optional, Dict, List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score

# ------- ä½ éœ€è¦å®‰è£… gseapy å’Œ seaborn -------
# pip install gseapy seaborn
from gseapy import gsva, get_library
import seaborn as sns

plt.rcParams["font.family"] = ["Arial"]
plt.rcParams["font.size"] = 12
CORE = ["geneid", "Symbol", "description"]


# ---------- é€šè·¯å‡å€¼çƒ­å›¾ï¼ˆå¸¦é€šè·¯å±‚æ¬¡æ ‘ï¼‰ ----------

def plot_gsva_means_clustermap(means_df: pd.DataFrame, out_png: Path):
    """
    å¯¹é€šè·¯Ã—cluster çš„å‡å€¼çŸ©é˜µåšè¡Œèšç±»ï¼Œç”»å‡ºå¸¦é€šè·¯å±‚æ¬¡æ ‘çš„çƒ­å›¾ï¼ˆç±»ä¼¼è®ºæ–‡ Fig.Bï¼‰ã€‚
    åˆ—ï¼ˆC1/C2/â€¦ï¼‰ä¸å†èšç±»ï¼Œä¿æŒ cluster é¡ºåºä¸å˜ã€‚
    """
    sns.set(context="notebook", font="Arial", font_scale=0.8)
    g = sns.clustermap(
        means_df,
        cmap="coolwarm",
        method="ward",
        metric="euclidean",
        # ğŸ‘‰ æŠŠå®½åº¦ä» 6 æåˆ° 10ï¼Œæ ‘å’Œçƒ­å›¾éƒ½æœ‰æ›´å¤šæ¨ªå‘ç©ºé—´
        figsize=(10, 12),
        row_cluster=True,
        col_cluster=False,
        linewidths=0.2,
        # ğŸ‘‰ æŠŠè¡Œ dendrogram çš„æ¯”ä¾‹è°ƒå¤§ä¸€ç‚¹ï¼ˆé»˜è®¤å¤§æ¦‚æ˜¯ 0.2 å·¦å³ï¼‰
        dendrogram_ratio=(0.3, 0.02),
        # ğŸ‘‰ æŠŠ colorbar å¾€å³ç§»ï¼Œåˆ«å å¤ªå¤šå·¦è¾¹ç©ºé—´
        cbar_pos=(0.9, 0.2, 0.02, 0.5),
    )
    out_png.parent.mkdir(parents=True, exist_ok=True)
    g.savefig(out_png, dpi=300)
    plt.close()


# ---------- I/O & é¢„å¤„ç† ----------

def read_gene_table(p: Path) -> pd.DataFrame:
    """
    è¯»å– label_?_fpkm_top20.csv
    index = (geneid, Symbol, description)
    åˆ— = æ ·æœ¬ï¼ˆslide_idï¼‰
    """
    df = pd.read_csv(p)
    for c in CORE:
        if c not in df.columns:
            raise RuntimeError(f"{p} ç¼ºå°‘åˆ—: {c}")
    df.set_index(CORE, inplace=True)
    return df


def log2_fpkm(df: pd.DataFrame) -> pd.DataFrame:
    """å¯¹ FPKM åš log2(FPKM+1)"""
    X = df.astype(float)
    return np.log2(X + 1.0)


def align_pos_neg(pos: pd.DataFrame, neg: pd.DataFrame) -> pd.DataFrame:
    """æŒ‰ index äº¤é›†å¯¹é½æ­£è´Ÿä¸¤ç»„ï¼Œç„¶åæ¨ªå‘æ‹¼æ¥ã€‚"""
    common = pos.index.intersection(neg.index)
    pos = pos.loc[common]
    neg = neg.loc[common]
    all_df = pd.concat([pos, neg], axis=1)
    return all_df


# ---------- Hallmark åŸºå› é›† ----------

def _read_gmt_simple(gmt_path: str) -> Dict[str, List[str]]:
    """ç®€æ˜“ GMT è§£æï¼šæ¯è¡Œ name  desc  gene1 gene2 ..."""
    gs = {}
    with open(gmt_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split("\t")
            if len(parts) >= 3:
                name = parts[0]
                genes = [g for g in parts[2:] if g]
                gs[name] = genes
    return gs


def load_hallmark_gene_sets(hallmark_gmt: Optional[str | Path]):
    """
    hallmark_gmt:
        - "auto"/None: ç”¨ gseapy.get_library("Hallmark","Human") åœ¨çº¿è·å–
        - å¦åˆ™è§†ä¸ºæœ¬åœ° .gmt è·¯å¾„
    è¿”å› dict{name:[gene symbols]}
    """
    if hallmark_gmt is None or str(hallmark_gmt).lower() == "auto":
        print("[GSVA] Using gseapy.get_library('Hallmark','Human') ...")
        return get_library(name="Hallmark", organism="Human")
    else:
        p = Path(hallmark_gmt)
        if not p.exists():
            raise FileNotFoundError(f"Hallmark GMT not found: {p}")
        print(f"[GSVA] Loading Hallmark from {p}")
        return _read_gmt_simple(str(p))


# ---------- ä¸º GSVA å‡†å¤‡è¡¨è¾¾çŸ©é˜µ ----------

def prep_expr_for_gsva(all_df: pd.DataFrame) -> pd.DataFrame:
    """
    å°† all_dfï¼ˆindex=MultiIndex[geneid, Symbol, description]
              columns=sampleï¼‰
    è½¬æˆ expr_symï¼ˆrows=Symbol, cols=sampleï¼‰ï¼ŒåŒå Symbol å–å‡å€¼ã€‚
    """
    df = all_df.reset_index()
    if "Symbol" not in df.columns:
        df["Symbol"] = df["geneid"].astype(str)
    expr_sym = df.groupby("Symbol")[all_df.columns].mean()
    expr_sym = expr_sym.dropna(how="all")
    return expr_sym


# ---------- ç”»æ™®é€šçƒ­å›¾ ----------

def _plot_heat_matrix(data: np.ndarray,
                      xticks: List[str],
                      yticks: List[str],
                      out_png: Path,
                      title: str):
    H, W = data.shape
    fig = plt.figure(figsize=(6, max(6, H * 0.25)))
    ax = plt.gca()
    im = ax.imshow(data, aspect="auto", cmap="coolwarm")
    plt.colorbar(im, fraction=0.046, pad=0.04)
    ax.set_xticks(np.arange(W))
    ax.set_xticklabels(xticks, rotation=0)
    ax.set_yticks(np.arange(H))
    ax.set_yticklabels(yticks, fontsize=6)
    plt.title(title, fontweight="bold")
    plt.tight_layout()
    out_png.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(out_png, dpi=300)
    plt.close()


# ---------- å…±è¯†èšç±»ï¼ˆConsensus Clustering, KMeans ç‰ˆæœ¬ï¼‰ ----------

def consensus_clustering_kmeans(
    X: np.ndarray,
    kmin: int = 2,
    kmax: int = 6,
    reps: int = 100,
    subsample_frac: float = 0.8,
    random_state: int = 2024
) -> Tuple[int, dict, np.ndarray, np.ndarray, dict]:
    """
    ç”¨ KMeans + é‡é‡‡æ ·åšå…±è¯†èšç±»ï¼ˆç±»ä¼¼ ConsensusClusterPlus çš„æ€æƒ³ï¼‰ï¼š

    å‚æ•°ï¼š
        X: (n_samples, n_features) çš„æ ·æœ¬ç‰¹å¾çŸ©é˜µï¼ˆè¿™é‡Œæ˜¯ GSVA çš„ pathways Ã— samples çš„è½¬ç½®ï¼‰
        kmin, kmax: åœ¨ [kmin, kmax] å†…æœç´¢æœ€ä½³ç°‡æ•° k
        reps: æ¯ä¸ª k é‡å¤èšç±»æ¬¡æ•°
        subsample_frac: æ¯æ¬¡é‡é‡‡æ ·ä½¿ç”¨çš„æ ·æœ¬æ¯”ä¾‹ï¼ˆä¾‹å¦‚ 0.8ï¼‰
        random_state: éšæœºç§å­

    è¿”å›ï¼š
        best_k:      å¹³å‡å…±è¯†åº¦æœ€é«˜çš„ k
        k_info:      {k: {"mean_consensus": float}}ï¼Œè®°å½•æ¯ä¸ª k çš„æŒ‡æ ‡
        labels:      æœ€ç»ˆç”¨ best_k åœ¨å…±è¯†çŸ©é˜µä¸Šåš KMeans å¾—åˆ°çš„ç°‡æ ‡ç­¾ï¼ˆé•¿åº¦ = n_samplesï¼‰
        consensus_best: best_k çš„å…±è¯†çŸ©é˜µï¼ˆn_samples Ã— n_samplesï¼‰
        consensus_all: {k: consensus_matrix_k}
    """
    n_samples = X.shape[0]
    rng = np.random.RandomState(random_state)

    k_info = {}
    consensus_all = {}
    best_k = None
    best_score = -np.inf

    for k in range(kmin, kmax + 1):
        print(f"[CC] Running consensus KMeans for k={k} ...")
        C = np.zeros((n_samples, n_samples), dtype=float)  # åŒç°‡æ¬¡æ•°
        M = np.zeros((n_samples, n_samples), dtype=float)  # è¢«åŒæ—¶é‡‡æ ·çš„æ¬¡æ•°

        for r in range(reps):
            # 1) éšæœºæŠ½å–éƒ¨åˆ†æ ·æœ¬
            n_sub = max(2, int(subsample_frac * n_samples))
            idx = rng.choice(n_samples, size=n_sub, replace=False)
            X_sub = X[idx]

            # 2) åœ¨å­æ ·æœ¬ä¸Š KMeans èšç±»
            km = KMeans(n_clusters=k, n_init=10, random_state=rng.randint(1_000_000_000))
            sub_labels = km.fit_predict(X_sub)

            # 3) æ›´æ–°åŒç°‡è®¡æ•° C å’Œå…±åŒå‡ºç°è®¡æ•° M
            #   åŒç°‡ï¼šåªå¯¹åŒä¸€ç°‡å†…çš„æ ·æœ¬ä¸¤ä¸¤åŠ  1
            for ci in range(k):
                members = idx[sub_labels == ci]
                m = len(members)
                if m <= 1:
                    continue
                for i in range(m):
                    for j in range(i + 1, m):
                        a = members[i]
                        b = members[j]
                        C[a, b] += 1
                        C[b, a] += 1

            #   è¢«åŒæ—¶é‡‡æ ·ï¼šå¯¹å­æ ·æœ¬ä¸­çš„æ‰€æœ‰ä¸¤ä¸¤ç»„åˆåŠ  1
            for i in range(n_sub):
                for j in range(i + 1, n_sub):
                    a = idx[i]
                    b = idx[j]
                    M[a, b] += 1
                    M[b, a] += 1

        # 4) è®¡ç®—å…±è¯†çŸ©é˜µï¼šconsensus = C / M
        with np.errstate(divide="ignore", invalid="ignore"):
            consensus = np.zeros_like(C)
            mask = M > 0
            consensus[mask] = C[mask] / M[mask]

        np.fill_diagonal(consensus, 1.0)

        # 5) ç»Ÿè®¡è¯¥ k çš„å¹³å‡å…±è¯†åº¦ï¼ˆä¸Šä¸‰è§’éå¯¹è§’å…ƒï¼‰
        tri = np.triu_indices(n_samples, k=1)
        vals = consensus[tri]
        mean_cons = float(np.nanmean(vals))
        print(f"[CC] k={k}: mean consensus = {mean_cons:.4f}")

        k_info[k] = {"mean_consensus": mean_cons}
        consensus_all[k] = consensus

        # 6) é€‰æ‹©å¹³å‡å…±è¯†åº¦æœ€é«˜çš„ k
        if mean_cons > best_score:
            best_score = mean_cons
            best_k = k

    print(f"[CC] Best k by mean consensus = {best_k} (score={best_score:.4f})")

    # 7) ç”¨ best_k å¯¹å¯¹åº”çš„å…±è¯†çŸ©é˜µå†åšä¸€æ¬¡ KMeans å¾—åˆ°æœ€ç»ˆ labels
    consensus_best = consensus_all[best_k]
    km_final = KMeans(n_clusters=best_k, n_init=50, random_state=random_state)
    labels = km_final.fit_predict(consensus_best)

    return best_k, k_info, labels, consensus_best, consensus_all


# ---------- ä¸»æµç¨‹ï¼šGSVA + å…±è¯†èšç±» ----------

def run_gsva_block(
    pos_csv: Path,
    neg_csv: Path,
    out_dir: Path,
    hallmark_gmt: Optional[str | Path],
    gsva_k: str | int = "auto"
):
    out_dir.mkdir(parents=True, exist_ok=True)

    # ----- 1. è¯» FPKM & log2 å˜æ¢ -----
    pos = read_gene_table(pos_csv)
    neg = read_gene_table(neg_csv)
    pos_t = log2_fpkm(pos)
    neg_t = log2_fpkm(neg)

    all_df = align_pos_neg(pos_t, neg_t)
    pos_cols = list(pos_t.columns)
    neg_cols = list(neg_t.columns)
    print(f"[GSVA] genes={all_df.shape[0]}, samples={all_df.shape[1]} (pos={len(pos_cols)}, neg={len(neg_cols)})")

    # ----- 2. å‡†å¤‡ Symbol çº§è¡¨è¾¾çŸ©é˜µ -----
    expr_sym = prep_expr_for_gsva(all_df)
    print(f"[GSVA] expr_sym: genes(Symbol)={expr_sym.shape[0]}, samples={expr_sym.shape[1]}")

    # ----- 3. åŠ è½½ Hallmark -----
    gene_sets = load_hallmark_gene_sets(hallmark_gmt)

    # ----- 4. è¿è¡Œ GSVA -----
    print("[GSVA] running gsva() ...")
    gsva_res = gsva(
        data=expr_sym,
        gene_sets=gene_sets,
        no_bootstrap=True,
        sample_norm=False,
        verbose=True,
        min_size=10,
        max_size=5000,
        processes=1,
    )

    # å…¼å®¹æ–°æ—§ç‰ˆæœ¬ gseapy
    if hasattr(gsva_res, "res2d"):
        df = gsva_res.res2d
    else:
        df = gsva_res  # æ—§ç‰ˆå¯èƒ½ç›´æ¥æ˜¯ DataFrame

    # æ–°ç‰ˆ gseapy.gsva è¿”å› long-formatï¼šName, Term, ES
    if set(df.columns) >= {"Name", "Term", "ES"}:
        print("[GSVA] Detected long-format GSVA output â†’ converting to wide matrix.")
        # index = pathway (Term), columns = sample (Name)
        gsva_scores = df.pivot(index="Term", columns="Name", values="ES")
    else:
        # å·²ç»æ˜¯ pathway Ã— sample çš„å®½çŸ©é˜µ
        gsva_scores = df

    gsva_scores = gsva_scores.astype(float)

    gsva_dir = out_dir / "GSVA"
    gsva_dir.mkdir(parents=True, exist_ok=True)
    gsva_scores.to_csv(gsva_dir / "gsva_scores_FPKM.csv")
    print(f"[GSVA] saved gsva_scores_FPKM.csv")

    # ----- 5. æ— ç›‘ç£å…±è¯†èšç±»ï¼ˆå®Œå…¨ä¸ä½¿ç”¨é¢„åæ ‡ç­¾é€‰ kï¼‰ -----
    X = gsva_scores.T.values  # samples x pathways
    n_samples = X.shape[0]

    if isinstance(gsva_k, str) and gsva_k.lower() == "auto":
        print("[CC] gsva_k='auto' â†’ running unsupervised consensus clustering (k=2..6) ...")
        best_k, k_info, labels, consensus_best, _ = consensus_clustering_kmeans(
            X,
            kmin=2,
            kmax=6,
            reps=100,
            subsample_frac=0.8,
            random_state=2024
        )
    else:
        k_int = int(gsva_k)
        print(f"[CC] gsva_k={k_int} â†’ running consensus clustering with fixed k={k_int} ...")
        best_k, k_info, labels, consensus_best, _ = consensus_clustering_kmeans(
            X,
            kmin=k_int,
            kmax=k_int,
            reps=100,
            subsample_frac=0.8,
            random_state=2024
        )

    # çœŸå®æ ‡ç­¾ï¼šå‰é¢æ˜¯åé¢„å(1)ï¼Œåé¢æ˜¯å¥½é¢„å(0)ï¼Œä»…ç”¨äºç»“æœè§£é‡Šå’Œ ARI è¯Šæ–­ï¼Œä¸å‚ä¸ä»»ä½•èšç±»ä¸é€‰ k
    true_y = np.array([1] * len(pos_cols) + [0] * len(neg_cols), dtype=int)
    ari = adjusted_rand_score(true_y, labels) if best_k >= 2 else np.nan

    # ä¿å­˜æ ·æœ¬èšç±»ç»“æœï¼ˆæ³¨æ„ï¼šcluster æ˜¯å®Œå…¨æ— ç›‘ç£å…±è¯†èšç±»çš„ç»“æœï¼‰
    assign_df = pd.DataFrame({
        "sample": list(gsva_scores.columns),
        "gsva_cluster": labels,
        "true_label": true_y
    })
    assign_df.to_csv(gsva_dir / "gsva_assign_FPKM.csv", index=False)
    print(f"[CC] saved gsva_assign_FPKM.csv")

    # ä¿å­˜ k é€‰æ‹©ä¿¡æ¯ + ARIï¼ˆä»…ä½œè¯Šæ–­å‚è€ƒï¼‰
    with open(gsva_dir / "gsva_stats_FPKM.txt", "w") as f:
        f.write("=== Unsupervised consensus clustering (KMeans-based) ===\n")
        f.write(f"n_samples = {n_samples}\n")
        f.write("k\tmean_consensus\n")
        for k in sorted(k_info.keys()):
            f.write(f"{k}\t{k_info[k]['mean_consensus']:.6f}\n")
        f.write(f"\nChosen_k (by max mean_consensus) = {best_k}\n")
        f.write(f"ARI(true_label vs gsva_cluster) = {ari:.6f}  # for diagnostic ONLY, not used for clustering\n")
    print(f"[CC] saved gsva_stats_FPKM.txt (k selection info)")

    # è‹¥éœ€è¦ï¼Œè¿˜å¯ä»¥æŠŠ best_k çš„å…±è¯†çŸ©é˜µç”»ä¸ªçƒ­å›¾
    _plot_heat_matrix(
        consensus_best,
        xticks=list(gsva_scores.columns),
        yticks=list(gsva_scores.columns),
        out_png=gsva_dir / f"consensus_k{best_k}.png",
        title=f"Consensus matrix (k={best_k})"
    )
    print(f"[CC] saved consensus_k{best_k}.png")

    # ----- 6. æŒ‰ cluster è®¡ç®— pathway å‡å€¼ï¼ˆç±»ä¼¼ Fig.B çš„çŸ©é˜µï¼‰ -----
    means = []
    for c in range(best_k):
        means.append(gsva_scores.iloc[:, labels == c].mean(axis=1))
    means_df = pd.concat(means, axis=1)
    means_df.columns = [f"C{i+1}" for i in range(best_k)]  # C1,C2,...
    means_df.to_csv(gsva_dir / "gsva_means_FPKM.csv")
    print(f"[GSVA] saved gsva_means_FPKM.csv")

    _plot_heat_matrix(
        means_df.values,
        xticks=list(means_df.columns),
        yticks=list(means_df.index),
        out_png=gsva_dir / "gsva_means_FPKM.png",
        title=f"GSVA pathway means (k={best_k}, FPKM)"
    )
    print(f"[GSVA] saved gsva_means_FPKM.png")

    # å¸¦é€šè·¯å±‚æ¬¡æ ‘çš„ç‰ˆæœ¬ï¼ˆç±»ä¼¼è®ºæ–‡ Fig.B å·¦ä¾§æ ‘ï¼‰
    plot_gsva_means_clustermap(
        means_df,
        gsva_dir / "gsva_means_FPKM_clustermap.png"
    )
    print(f"[GSVA] saved gsva_means_FPKM_clustermap.png")

    # ----- 7. æ ·æœ¬å±‚é¢çš„ GSVA çƒ­å›¾ï¼ˆæŒ‰æ— ç›‘ç£ cluster æ’åºï¼‰ -----
    order = np.argsort(labels)
    S_ord = gsva_scores.iloc[:, order]
    xticks = [f"{S_ord.columns[i]}(C{labels[order[i]]+1})" for i in range(S_ord.shape[1])]
    _plot_heat_matrix(
        S_ord.values,
        xticks=xticks,
        yticks=list(S_ord.index),
        out_png=gsva_dir / "gsva_samples_FPKM.png",
        title=f"GSVA scores (samples ordered by unsupervised cluster, k={best_k}, FPKM)"
    )
    print(f"[GSVA] saved gsva_samples_FPKM.png")


def main():
    ap = argparse.ArgumentParser(description="Standalone GSVA + unsupervised consensus clustering on FPKM top20 files")
    ap.add_argument("--fpkm_pos", type=Path, required=True,
                    help="label_1_fpkm_top20.csv (bad prognosis = 1)")
    ap.add_argument("--fpkm_neg", type=Path, required=True,
                    help="label_0_fpkm_top20.csv (good prognosis = 0)")
    ap.add_argument("--out_dir", type=Path, required=True,
                    help="output directory")
    ap.add_argument("--hallmark_gmt", type=str, default="auto",
                    help="'auto' or path to local Hallmark .gmt")
    ap.add_argument("--gsva_k", type=str, default="auto",
                    help="If integer (e.g. '2' or '3'): run consensus clustering with fixed k; "
                         "if 'auto': search k in [2..6] by mean consensus (unsupervised).")
    args = ap.parse_args()

    run_gsva_block(
        pos_csv=args.fpkm_pos,
        neg_csv=args.fpkm_neg,
        out_dir=args.out_dir,
        hallmark_gmt=args.hallmark_gmt,
        gsva_k=args.gsva_k,
    )


if __name__ == "__main__":
    main()
