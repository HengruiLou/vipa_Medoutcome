{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa796a35-15f7-4200-8664-95a0696e504e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:23:14.854355Z",
     "start_time": "2024-07-25T13:23:14.432781Z"
    }
   },
   "outputs": [],
   "source": [
    "import openslide\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadf00ac-5cd5-4632-8451-1e1b478904b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:23:14.938653Z",
     "start_time": "2024-07-25T13:23:14.937417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "128"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slides = glob.glob('/mnt/s3/lhm/HCC/*/*.mrxs')\n",
    "len(slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9652dbba-8a8b-4965-8fc2-ec4d70eb367e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:23:16.733589Z",
     "start_time": "2024-07-25T13:23:16.732927Z"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, Pipe, freeze_support\n",
    "\n",
    "#=============================================================#\n",
    "# 接口                                                        #\n",
    "#-------------------------------------------------------------#\n",
    "#   multi_process_exec 多进程执行                             #\n",
    "#   multi_thread_exec  多线程执行                             #\n",
    "#-------------------------------------------------------------#\n",
    "# 参数：                                                      #\n",
    "#   f         (function): 批量执行的函数                      #\n",
    "#   args_mat  (list)    : 批量执行的参数                      #\n",
    "#   pool_size (int)     : 进程/线程池的大小                   #\n",
    "#   desc      (str)     : 进度条的描述文字                    #\n",
    "#-------------------------------------------------------------#\n",
    "# 例子：                                                      #\n",
    "# >>> def Pow(a,n):        ← 定义一个函数（可以有多个参数）   #\n",
    "# ...     return a**n                                         #\n",
    "# >>>                                                         #\n",
    "# >>> args_mat=[[2,1],     ← 批量计算 Pow(2,1)                #\n",
    "# ...           [2,2],                Pow(2,2)                #\n",
    "# ...           [2,3],                Pow(2,3)                #\n",
    "# ...           [2,4],                Pow(2,4)                #\n",
    "# ...           [2,5],                Pow(2,5)                #\n",
    "# ...           [2,6]]                Pow(2,6)                #\n",
    "# >>>                                                         #\n",
    "# >>> results=multi_thread_exec(Pow,args_mat,desc='计算中')   #\n",
    "# 计算中: 100%|█████████████| 6/6 [00:00<00:00, 20610.83it/s] #\n",
    "# >>>                                                         #\n",
    "# >>> print(results)                                          #\n",
    "# [2, 4, 8, 16, 32, 64]                                       #\n",
    "#-------------------------------------------------------------#\n",
    "\n",
    "ToBatch = lambda arr, size: [arr[i * size:(i + 1) * size] for i in range((size - 1 + len(arr)) // size)]\n",
    "\n",
    "\n",
    "def batch_exec(f, args_batch, w):\n",
    "    results = []\n",
    "    for i, args in enumerate(args_batch):\n",
    "        try:\n",
    "            if isinstance(args, (list, tuple, dict)):\n",
    "                ans = f(*args)\n",
    "            else:\n",
    "                ans = f(args)\n",
    "            results.append(ans)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            results.append(None)\n",
    "        w.send(1)\n",
    "    return results\n",
    "\n",
    "\n",
    "def multi_process_exec(f, args_mat, pool_size=5, desc=None):\n",
    "    if len(args_mat) == 0: return []\n",
    "    batch_size = max(1, int(len(args_mat) / 4 / pool_size))\n",
    "    results = []\n",
    "    args_batches = ToBatch(args_mat, batch_size)\n",
    "    with tqdm(total=len(args_mat), desc=desc) as pbar:\n",
    "        with Pool(processes=pool_size) as pool:\n",
    "            r, w = Pipe(duplex=False)\n",
    "            pool_rets = []\n",
    "            for i, args_batch in enumerate(args_batches):\n",
    "                pool_rets.append(pool.apply_async(batch_exec, (f, args_batch, w)))\n",
    "            cnt = 0\n",
    "            while cnt < len(args_mat):\n",
    "                try:\n",
    "                    msg = r.recv()\n",
    "                    pbar.update(1)\n",
    "                    cnt += 1\n",
    "                except EOFError:\n",
    "                    print('EOFError')\n",
    "                    break\n",
    "            for ret in pool_rets:\n",
    "                for r in ret.get():\n",
    "                    results.append(r)\n",
    "    return results\n",
    "\n",
    "\n",
    "def multi_thread_exec(f, args_mat, pool_size=5, desc=None):\n",
    "    if len(args_mat) == 0: return []\n",
    "    results = [None for _ in range(len(args_mat))]\n",
    "    with tqdm(total=len(args_mat), desc=desc) as pbar:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=pool_size) as executor:\n",
    "            futures = {executor.submit(f, *args): i for i, args in enumerate(args_mat)}\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                i = futures[future]\n",
    "                ret = future.result()\n",
    "                results[i] = ret\n",
    "                pbar.update(1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fc37a2-94a3-407d-a6af-31854af7bc47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-19T07:02:49.406930Z",
     "start_time": "2024-07-19T07:02:46.227271Z"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "from itertools import repeat\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.segmentation import slic, mark_boundaries\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def convert_numpy_img_to_superpixel_graph(img, code, polygons, slic_kwargs={}):\n",
    "    # img  = cv2.resize(img,(img.shape[1]//3,img.shape[0]//3))\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    n = 1024\n",
    "    hsv_image = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower_white = np.array([0, 0, 220])  # 假设threshold是一个你选择的值\n",
    "    upper_white = np.array([180, 255, 255])\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([180, 255, 50])\n",
    "    # 创建掩模来分离白色和黑色背景\n",
    "    mask1 = cv2.inRange(hsv_image, lower_white, upper_white)\n",
    "    mask2 = cv2.inRange(hsv_image, lower_black, upper_black)\n",
    "    # 使用 cv2.bitwise_or 来合并掩模\n",
    "    mask = 255 - cv2.bitwise_or(mask1, mask2)\n",
    "    kernel = np.ones((10, 10), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.erode(mask, kernel, iterations=2)\n",
    "    #缩小图像\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    max_area = 0\n",
    "    max_contour = None\n",
    "    xm = 0\n",
    "    ym = 0\n",
    "    height, width = img.shape[:2]\n",
    "    # 遍历轮廓，找到面积最大的外接矩形\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = w * h\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            max_contour = contour\n",
    "\n",
    "    if max_contour is not None:\n",
    "        xm, ym, w, h = cv2.boundingRect(max_contour)\n",
    "        mask = mask[ym:ym + h, xm:xm + w]\n",
    "        hsv_image = hsv_image[ym:ym + h, xm:xm + w, :]\n",
    "        img_org = img.copy()\n",
    "        img = img[ym:ym + h, xm:xm + w, :]\n",
    "        height, width = h, w\n",
    "    mask = mask / 255\n",
    "    segments = slic(img, n_segments=n, slic_zero=True, compactness=10, start_label=0,\n",
    "                    enforce_connectivity=True, convert2lab=True, sigma=0.7,\n",
    "                    mask=mask, **slic_kwargs)\n",
    "    np.save(f\"/mnt/s3/lhm/HCC_seg_1/{code}.npy\", segments)\n",
    "    num_of_nodes = np.max(segments) + 1\n",
    "    nodes = {node: {\"rgb_list\": [], \"r\": [], \"g\": [], \"b\": [], } for node in range(num_of_nodes)}\n",
    "    # get rgb values and positions\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            node = segments[y, x]\n",
    "            if node < 0:\n",
    "                continue\n",
    "            rgb = img[y, x, :]\n",
    "            nodes[node][\"r\"].append(rgb[2])\n",
    "            nodes[node][\"g\"].append(rgb[1])\n",
    "            nodes[node][\"b\"].append(rgb[0])\n",
    "    for node in nodes:\n",
    "        r_bin = np.bincount(nodes[node][\"r\"])\n",
    "        r_bin = np.pad(r_bin, (0, 256 - len(r_bin)), 'constant', constant_values=(0, 0))\n",
    "        g_bin = np.bincount(nodes[node][\"g\"])\n",
    "        g_bin = np.pad(g_bin, (0, 256 - len(g_bin)), 'constant', constant_values=(0, 0))\n",
    "        b_bin = np.bincount(nodes[node][\"b\"])\n",
    "        b_bin = np.pad(b_bin, (0, 256 - len(b_bin)), 'constant', constant_values=(0, 0))\n",
    "        nodes[node][\"rgb_list\"] = np.stack([r_bin, g_bin, b_bin]).ravel()\n",
    "    G = nx.Graph()\n",
    "    # compute node positions\n",
    "    segments_ids = np.unique(segments)\n",
    "    segments_ids = np.delete(segments_ids, np.where(segments_ids == -1))\n",
    "    pos = np.array([np.mean(np.nonzero(segments == i), axis=1) for i in segments_ids])\n",
    "    pos[:, 0] += ym\n",
    "    pos[:, 1] += xm\n",
    "    pos = pos * 64\n",
    "    pos = pos.astype(int)\n",
    "    #pos[0]为height_y pos[1]为width_x\n",
    "    for node in nodes:\n",
    "        feature = nodes[node]['rgb_list']\n",
    "        label = False\n",
    "        for p in polygons:\n",
    "            p = np.array(p, dtype=np.int32)\n",
    "            label = cv2.pointPolygonTest(p, (int(pos[node][1]), int(pos[node][0])), True) > 0\n",
    "        G.add_node(node, features=feature, label=label)\n",
    "    # add edges\n",
    "    vs_right = np.vstack([segments[:, :-1].ravel(), segments[:, 1:].ravel()])\n",
    "    vs_below = np.vstack([segments[:-1, :].ravel(), segments[1:, :].ravel()])\n",
    "    bneighbors = np.unique(np.hstack([vs_right, vs_below]), axis=1)\n",
    "    for i in range(bneighbors.shape[1]):\n",
    "        if bneighbors[0, i] == -1 or bneighbors[1, i] == -1:\n",
    "            continue\n",
    "        if bneighbors[0, i] != bneighbors[1, i]:\n",
    "            G.add_edge(bneighbors[0, i], bneighbors[1, i])\n",
    "    # add self loops\n",
    "    for node in nodes:\n",
    "        G.add_edge(node, node)\n",
    "\n",
    "    # get edge_index\n",
    "    m = len(G.edges)\n",
    "    edge_index = np.zeros([2 * m, 2]).astype(np.int64)\n",
    "    for e, (s, t) in enumerate(G.edges):\n",
    "        edge_index[e, 0] = s\n",
    "        edge_index[e, 1] = t\n",
    "        edge_index[m + e, 0] = t\n",
    "        edge_index[m + e, 1] = s\n",
    "    # get features\n",
    "    num_of_features = 768\n",
    "    x = np.zeros([1024, num_of_features]).astype(np.float32)\n",
    "    y = np.zeros(1024).astype(np.float32)\n",
    "    for node in G.nodes:\n",
    "        if node >= 1024:\n",
    "            continue\n",
    "        x[node] = G.nodes[node][\"features\"]\n",
    "        y[node] = G.nodes[node][\"label\"]\n",
    "    return x, y, edge_index, pos, [ym, xm], [height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca93e16-72a2-4868-b1f8-196c73d15ec8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:29:02.160976Z",
     "start_time": "2024-07-18T07:29:02.070385Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.utils_single import read_points_from_xml\n",
    "\n",
    "\n",
    "def process_img(i):\n",
    "    img = cv2.imread(i)\n",
    "    name = i.split('/')[-1].split('.')[0]\n",
    "    label = i.split('/')[-2]\n",
    "    if 'M' in name and name[-1] == '-':\n",
    "        name = name[:-1]\n",
    "    polygons = []\n",
    "    if os.path.exists('/mnt/s3/lhm/HCC' + '/xml/' + f'{name}_Annotations.xml'):\n",
    "        polygons = read_points_from_xml(liver_name=f'{name}_Annotations.xml', scale=1,\n",
    "                                        xml_path='/mnt/s3/lhm/HCC' + '/xml/',\n",
    "                                        dataset='HCC_LOWER')\n",
    "    x, y, edge_index, pos, offset, size = convert_numpy_img_to_superpixel_graph(img, name, polygons)\n",
    "    res = dict({})\n",
    "    res['x'] = x\n",
    "    res['edge'] = edge_index\n",
    "    res['pos'] = pos\n",
    "    res['code'] = name\n",
    "    res['y'] = label\n",
    "    res['nodey'] = y\n",
    "    res['offset'] = offset\n",
    "    res['size'] = size\n",
    "    np.save(f'/mnt/s3/lhm/HCC_level_1/{name}.npy', res, allow_pickle=True)\n",
    "\n",
    "# process_img('/mnt/storage/lhm/HCC_thumb/0/6M01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ec3d5ffd-d05a-4aad-9c1a-ffb3cc87b8b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:09:31.028403Z",
     "start_time": "2024-07-18T04:09:05.019915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4267, 1830, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[61], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m args_mat \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/mnt/s3/lhm/HCC_thumb/*/*.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m args_mat:\n\u001B[0;32m----> 3\u001B[0m     \u001B[43mprocess_img\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[60], line 15\u001B[0m, in \u001B[0;36mprocess_img\u001B[0;34m(i)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/mnt/s3/lhm/HCC\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/xml/\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_Annotations.xml\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m     12\u001B[0m     polygons \u001B[38;5;241m=\u001B[39m read_points_from_xml(liver_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_Annotations.xml\u001B[39m\u001B[38;5;124m'\u001B[39m, scale\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     13\u001B[0m                                     xml_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/mnt/s3/lhm/HCC\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/xml/\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     14\u001B[0m                                     dataset\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHCC_LOWER\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m x, y, edge_index, pos, offset,size \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_numpy_img_to_superpixel_graph\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolygons\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m({})\n\u001B[1;32m     17\u001B[0m res[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m x\n",
      "Cell \u001B[0;32mIn[57], line 58\u001B[0m, in \u001B[0;36mconvert_numpy_img_to_superpixel_graph\u001B[0;34m(img, code, polygons, slic_kwargs)\u001B[0m\n\u001B[1;32m     56\u001B[0m     height, width \u001B[38;5;241m=\u001B[39m h, w\n\u001B[1;32m     57\u001B[0m mask \u001B[38;5;241m=\u001B[39m mask \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m255\u001B[39m\n\u001B[0;32m---> 58\u001B[0m segments \u001B[38;5;241m=\u001B[39m \u001B[43mslic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_segments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mslic_zero\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompactness\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m                \u001B[49m\u001B[43menforce_connectivity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert2lab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.7\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m                \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mslic_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m np\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/s3/lhm/HCC_seg_1/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m\"\u001B[39m, segments)\n\u001B[1;32m     62\u001B[0m num_of_nodes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmax(segments) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/skimage/_shared/utils.py:316\u001B[0m, in \u001B[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    313\u001B[0m channel_axis \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchannel_axis\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    315\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m channel_axis \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001B[39;00m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(channel_axis):\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/skimage/segmentation/slic_superpixels.py:322\u001B[0m, in \u001B[0;36mslic\u001B[0;34m(image, n_segments, compactness, max_num_iter, sigma, spacing, convert2lab, enforce_connectivity, min_size_factor, max_size_factor, slic_zero, start_label, mask, channel_axis)\u001B[0m\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m image\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m3\u001B[39m]:\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage and mask should have the same shape.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 322\u001B[0m     centroids, steps \u001B[38;5;241m=\u001B[39m \u001B[43m_get_mask_centroids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_segments\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultichannel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    323\u001B[0m     update_centroids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    324\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/skimage/segmentation/slic_superpixels.py:64\u001B[0m, in \u001B[0;36m_get_mask_centroids\u001B[0;34m(mask, n_centroids, multichannel)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     63\u001B[0m     idx_dense \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mEllipsis\u001B[39m\n\u001B[0;32m---> 64\u001B[0m centroids, _ \u001B[38;5;241m=\u001B[39m \u001B[43mkmeans2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoord\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx_dense\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcoord\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m# Compute the minimum distance of each centroid to the others\u001B[39;00m\n\u001B[1;32m     67\u001B[0m dist \u001B[38;5;241m=\u001B[39m squareform(pdist(centroids))\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/scipy/cluster/vq.py:786\u001B[0m, in \u001B[0;36mkmeans2\u001B[0;34m(data, k, iter, thresh, minit, missing, check_finite, seed)\u001B[0m\n\u001B[1;32m    782\u001B[0m         code_book \u001B[38;5;241m=\u001B[39m init_meth(data, k, rng)\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28miter\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Compute the nearest neighbor for each obs using the current code book\u001B[39;00m\n\u001B[0;32m--> 786\u001B[0m     label \u001B[38;5;241m=\u001B[39m \u001B[43mvq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcode_book\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;66;03m# Update the code book by computing centroids\u001B[39;00m\n\u001B[1;32m    788\u001B[0m     new_code_book, has_members \u001B[38;5;241m=\u001B[39m _vq\u001B[38;5;241m.\u001B[39mupdate_cluster_means(data, label, nc)\n",
      "File \u001B[0;32m~/miniconda3/envs/pytorch/lib/python3.8/site-packages/scipy/cluster/vq.py:209\u001B[0m, in \u001B[0;36mvq\u001B[0;34m(obs, code_book, check_finite)\u001B[0m\n\u001B[1;32m    206\u001B[0m c_code_book \u001B[38;5;241m=\u001B[39m code_book\u001B[38;5;241m.\u001B[39mastype(ct, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(ct, np\u001B[38;5;241m.\u001B[39mfloat64) \u001B[38;5;129;01mor\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(ct, np\u001B[38;5;241m.\u001B[39mfloat32):\n\u001B[0;32m--> 209\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_vq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc_obs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc_code_book\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m py_vq(obs, code_book, check_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "args_mat = glob.glob('/mnt/s3/lhm/HCC_thumb/*/*.png')\n",
    "for i in args_mat:\n",
    "    process_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54551cf-ed1f-4228-a5da-9c9d30f03fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T07:32:48.299247Z",
     "start_time": "2024-07-18T07:29:03.996221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "processing:   0%|          | 0/128 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fe990f48d0143b0af409fa7f2efe84e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhm/miniconda3/envs/pytorch/lib/python3.8/site-packages/scipy/cluster/vq.py:602: UserWarning: One of the clusters is empty. Re-run kmeans with a different initialization.\n",
      "  warnings.warn(\"One of the clusters is empty. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": "[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_mat = glob.glob('/mnt/s3/lhm/HCC_thumb/*/*.png')\n",
    "multi_process_exec(process_img, args_mat, 32, desc='processing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6bac6a9-89aa-4944-adbe-2a7f5ddd3db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T04:14:58.301484Z",
     "start_time": "2024-07-18T04:14:58.300681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': array([[ 0.,  0.,  0., ..., 16., 15., 26.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), 'edge': array([[   0,   11],\n",
      "       [   0,   12],\n",
      "       [   0,   20],\n",
      "       ...,\n",
      "       [1019, 1019],\n",
      "       [1020, 1020],\n",
      "       [1021, 1021]]), 'pos': array([[ 65287,  61301],\n",
      "       [ 65847,  93817],\n",
      "       [ 66340,  91014],\n",
      "       ...,\n",
      "       [176245,  90067],\n",
      "       [177351,  89224],\n",
      "       [177408,  80576]]), 'code': '201251654', 'y': '2', 'nodey': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'offset': [988, 570], 'size': (4267, 1830)}\n",
      "Counter({1.0: 716, 0.0: 308})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = np.load('/mnt/s3/lhm/HCC_level_1/201251654.npy', allow_pickle=True).item()\n",
    "print(a)\n",
    "print(Counter(a['nodey']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14c6dd39-6fb2-4289-8e80-457d214d8e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T03:54:57.956414Z",
     "start_time": "2024-07-18T03:54:40.824840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'edge': array([[   0,    1],\n",
      "       [   0,    3],\n",
      "       [   0,    5],\n",
      "       ...,\n",
      "       [1023, 1022],\n",
      "       [1022, 1022],\n",
      "       [1023, 1023]]), 'pos': array([[ 59897,  77674],\n",
      "       [ 60763,  74870],\n",
      "       [ 61719,  71800],\n",
      "       ...,\n",
      "       [156520,  20019],\n",
      "       [157256,  17705],\n",
      "       [157927,  15318]]), 'code': '6M0', 'y': '0', 'nodey': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 'offset': [908, 140]}\n"
     ]
    }
   ],
   "source": [
    "process_img('/mnt/s3/lhm/HCC_thumb/0/6M01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f5dfc6-20a9-440a-a6bf-d4d6cdf146de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
